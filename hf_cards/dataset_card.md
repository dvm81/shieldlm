---
language:
  - en
  - fr
  - de
  - es
  - it
  - pt
  - ro
license: mit
task_categories:
  - text-classification
tags:
  - prompt-injection
  - ai-safety
  - llm-security
  - jailbreak
  - adversarial
size_categories:
  - 10K<n<100K
---

# ShieldLM Prompt Injection Dataset

A unified prompt injection detection dataset spanning **three attack categories**: direct injection, indirect injection, and jailbreak. Curated from 9 source datasets with a 3-level hierarchical label schema.

## Dataset Description

### Purpose

Training and evaluating prompt injection classifiers for production deployment. Designed to address gaps in existing datasets:

- **Indirect injection** coverage (via InjecAgent tool-embedded attacks)
- **Application-structured benign data** (prevents format-based false positives)
- **Sensitive-topic stress tests** (via JailbreakBench — topics != techniques)

### Label Schema

| Level | Field | Values |
|-------|-------|--------|
| 1 (Binary) | `label_binary` | 0 (BENIGN), 1 (ATTACK) |
| 2 (Category) | `label_category` | benign, direct_injection, indirect_injection, jailbreak |
| 3 (Intent) | `label_intent` | goal_hijacking, data_exfiltration, financial_harm, ... |

### Source Datasets

| Source | License | Category | Samples |
|--------|---------|----------|---------|
| deepset/prompt-injections | Apache-2.0 | direct_injection + benign | ~662 |
| Harelix/Prompt-Injection-Mixed-Techniques-2024 | Apache-2.0 | direct_injection + benign | ~1,174 |
| reshabhs/SPML_Chatbot_Prompt_Injection | CC-BY-4.0 | direct_injection + benign | ~7,000 |
| xTRam1/safe-guard-prompt-injection | Apache-2.0 | direct_injection + benign | ~3,000 |
| yanismiraoui/prompt_injections | Apache-2.0 | direct_injection (multilingual) | ~1,000 |
| JailbreakBench/JBB-Behaviors | MIT | benign (FP stress test) | ~200 |
| jackhhao/jailbreak-classification | MIT | jailbreak + benign | ~1,000 |
| alespalla/chatbot_instruction_prompts | Apache-2.0 | benign (conversational) | up to 8,000 |
| InjecAgent (UIUC) | MIT | indirect_injection + benign | ~1,054 |

### Key Design Decisions

1. **JailbreakBench Goals are labeled BENIGN** — they describe harmful topics, not injection techniques. Used as a false-positive stress test.
2. **No isolated attacker payloads** from InjecAgent — context determines injection (PromptShield insight).
3. **Benign data includes application-structured samples** — clean tool responses from InjecAgent prevent the classifier from learning "JSON format = attack."

### Fields

| Field | Type | Description |
|-------|------|-------------|
| `id` | string | Deterministic unique ID: `{source}_{index}_{hash}` |
| `text` | string | Text to classify |
| `label_binary` | int | 0 (BENIGN) or 1 (ATTACK) |
| `label_category` | string | One of 4 categories |
| `label_intent` | string (nullable) | Fine-grained attack intent |
| `source` | string | Origin dataset |
| `language` | string | ISO 639-1 language code |
| `context` | string (nullable) | System prompt or user instruction |
| `metadata` | dict | Source-specific metadata |

### Splits

| Split | Purpose |
|-------|---------|
| train | Model training (70%) |
| validation | Threshold calibration and model selection (15%) |
| test | Final evaluation (15%) |

Stratified by `label_category`, random seed 42.

## Intended Use

- Training prompt injection detection classifiers
- Benchmarking detection systems at low-FPR operating points
- Research on adversarial robustness of LLM safety filters

## Limitations

- **English-dominant**: Multilingual samples are limited (~7 languages)
- **Text-only**: No multimodal or visual prompt injection
- **Synthetic benign tool responses**: Generated by stripping injections from InjecAgent
- **Static benchmark**: Does not capture evolving attack techniques
- **No multi-turn**: All samples are single-turn

## Citation

```bibtex
@software{shieldlm2026,
  author = {Milushev, Dimiter},
  title = {ShieldLM: Unified Prompt Injection Detection Dataset},
  year = {2026},
  url = {https://github.com/dvm81/shieldlm}
}
```

## License

MIT (this curation). Source datasets retain their original licenses (see table above).
